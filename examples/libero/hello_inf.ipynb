{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2bb5b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/ns1254/openpi/examples/libero/.venv/lib/python3.8/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import dataclasses\n",
    "import logging\n",
    "import math\n",
    "import pathlib\n",
    "\n",
    "import os \n",
    "\n",
    "libero_path  = \"/home/ns1254/openpi/third_party/libero\"\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(libero_path)\n",
    "\n",
    "\n",
    "import imageio\n",
    "from libero.libero import benchmark\n",
    "from libero.libero import get_libero_path\n",
    "from libero.libero.envs import OffScreenRenderEnv\n",
    "import numpy as np\n",
    "from openpi_client import image_tools\n",
    "from openpi_client import websocket_client_policy as _websocket_client_policy\n",
    "import tqdm\n",
    "import tyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIBERO_DUMMY_ACTION = [0.0] * 6 + [-1.0]\n",
    "LIBERO_ENV_RESOLUTION = 256  # resolution used to render training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "292422e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class Args:\n",
    "    #################################################################################################################\n",
    "    # Model server parameters\n",
    "    #################################################################################################################\n",
    "    host: str = \"0.0.0.0\"\n",
    "    port: int = 8000\n",
    "    resize_size: int = 224\n",
    "    replan_steps: int = 5\n",
    "\n",
    "    #################################################################################################################\n",
    "    # LIBERO environment-specific parameters\n",
    "    #################################################################################################################\n",
    "    task_suite_name: str = (\n",
    "        \"libero_spatial\"  # Task suite. Options: libero_spatial, libero_object, libero_goal, libero_10, libero_90\n",
    "    )\n",
    "    num_steps_wait: int = 10  # Number of steps to wait for objects to stabilize i n sim\n",
    "    num_trials_per_task: int = 5   # Number of rollouts per task\n",
    "\n",
    "    #################################################################################################################\n",
    "    # Utils\n",
    "    #################################################################################################################\n",
    "    video_out_path: str = \"data/libero/videos\"  # Path to save videos\n",
    "\n",
    "    seed: int = 7  # Random Seed (for reproducibility)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f690c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_libero_env(task, resolution, seed):\n",
    "    \"\"\"Initializes and returns the LIBERO environment, along with the task description.\"\"\"\n",
    "    task_description = task.language\n",
    "    task_bddl_file = pathlib.Path(get_libero_path(\"bddl_files\")) / task.problem_folder / task.bddl_file\n",
    "    env_args = {\"bddl_file_name\": task_bddl_file, \"camera_heights\": resolution, \"camera_widths\": resolution}\n",
    "    env = OffScreenRenderEnv(**env_args)\n",
    "    env.seed(seed)  # IMPORTANT: seed seems to affect object positions even when using fixed initial state\n",
    "    return env, task_description\n",
    "\n",
    "def _quat2axisangle(quat):\n",
    "    \"\"\"\n",
    "    Copied from robosuite: https://github.com/ARISE-Initiative/robosuite/blob/eafb81f54ffc104f905ee48a16bb15f059176ad3/robosuite/utils/transform_utils.py#L490C1-L512C55\n",
    "    \"\"\"\n",
    "    # clip quaternion\n",
    "    if quat[3] > 1.0:\n",
    "        quat[3] = 1.0\n",
    "    elif quat[3] < -1.0:\n",
    "        quat[3] = -1.0\n",
    "\n",
    "    den = np.sqrt(1.0 - quat[3] * quat[3])\n",
    "    if math.isclose(den, 0.0):\n",
    "        # This is (close to) a zero degree rotation, immediately return\n",
    "        return np.zeros(3)\n",
    "\n",
    "    return (quat[:3] * 2.0 * math.acos(quat[3])) / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b4ea4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args= Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a03b665a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "# Initialize LIBERO task suite\n",
    "benchmark_dict = benchmark.get_benchmark_dict()\n",
    "task_suite = benchmark_dict[args.task_suite_name]()\n",
    "num_tasks_in_suite = task_suite.n_tasks\n",
    "logging.info(f\"Task suite: {args.task_suite_name}\")\n",
    "\n",
    "pathlib.Path(args.video_out_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if args.task_suite_name == \"libero_spatial\":\n",
    "    max_steps = 220  # longest training demo has 193 steps\n",
    "elif args.task_suite_name == \"libero_object\":\n",
    "    max_steps = 280  # longest training demo has 254 steps\n",
    "elif args.task_suite_name == \"libero_goal\":\n",
    "    max_steps = 300  # longest training demo has 270 steps\n",
    "elif args.task_suite_name == \"libero_10\":\n",
    "    max_steps = 520  # longest training demo has 505 steps\n",
    "elif args.task_suite_name == \"libero_90\":\n",
    "    max_steps = 400  # longest training demo has 373 steps\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task suite: {args.task_suite_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9c26ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = _websocket_client_policy.WebsocketClientPolicy(args.host, args.port)\n",
    "\n",
    "# Start evaluation\n",
    "total_episodes, total_successes = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "122982dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tasks_in_suite\n",
    "task_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aad2d244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning]: datasets path /home/ns1254/LIBERO/libero/libero/../datasets does not exist!\n",
      "[Warning]: datasets path /home/ns1254/LIBERO/libero/libero/../datasets does not exist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ns1254/openpi/examples/libero/.venv/lib/python3.8/site-packages/numba/np/arraymath.py:3845: DeprecationWarning: `np.MachAr` is deprecated (NumPy 1.22).\n",
      "  @overload(np.MachAr)\n"
     ]
    }
   ],
   "source": [
    "task = task_suite.get_task(task_id)\n",
    "\n",
    "# Get default LIBERO initial states\n",
    "initial_states = task_suite.get_task_init_states(task_id)\n",
    "\n",
    "# Initialize LIBERO environment and task description\n",
    "env, task_description = _get_libero_env(task, LIBERO_ENV_RESOLUTION, args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b94611c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.num_trials_per_task\n",
    "episode_idx = 0\n",
    "task_episodes, task_successes = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "687075e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"\\nTask: {task_description}\")\n",
    "\n",
    "# Reset environment\n",
    "env.reset()\n",
    "action_plan = collections.deque()\n",
    "\n",
    "# Set initial states\n",
    "obs = env.set_init_state(initial_states[episode_idx])\n",
    "\n",
    "# Setup\n",
    "t = 0\n",
    "replay_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "face7e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Starting episode {task_episodes+1}...\")\n",
    "while t < max_steps + args.num_steps_wait:\n",
    "    try:\n",
    "        # IMPORTANT: Do nothing for the first few timesteps because the simulator drops objects\n",
    "        # and we need to wait for them to fall\n",
    "        if t < args.num_steps_wait:\n",
    "            obs, reward, done, info = env.step(LIBERO_DUMMY_ACTION)\n",
    "            t += 1\n",
    "            continue\n",
    "\n",
    "        # Get preprocessed image\n",
    "        # IMPORTANT: rotate 180 degrees to match train preprocessing\n",
    "        img = np.ascontiguousarray(obs[\"agentview_image\"][::-1, ::-1])\n",
    "        wrist_img = np.ascontiguousarray(obs[\"robot0_eye_in_hand_image\"][::-1, ::-1])\n",
    "        img = image_tools.convert_to_uint8(\n",
    "            image_tools.resize_with_pad(img, args.resize_size, args.resize_size)\n",
    "        )\n",
    "        wrist_img = image_tools.convert_to_uint8(\n",
    "            image_tools.resize_with_pad(wrist_img, args.resize_size, args.resize_size)\n",
    "        )\n",
    "\n",
    "        # Save preprocessed image for replay video\n",
    "        replay_images.append(img)\n",
    "\n",
    "        if not action_plan:\n",
    "            # Finished executing previous action chunk -- compute new chunk\n",
    "            # Prepare observations dict\n",
    "            element = {\n",
    "                \"observation/image\": img,\n",
    "                \"observation/wrist_image\": wrist_img,\n",
    "                \"observation/state\": np.concatenate(\n",
    "                    (\n",
    "                        obs[\"robot0_eef_pos\"],\n",
    "                        _quat2axisangle(obs[\"robot0_eef_quat\"]),\n",
    "                        obs[\"robot0_gripper_qpos\"],\n",
    "                    )\n",
    "                ),\n",
    "                \"prompt\": str(task_description),\n",
    "            }\n",
    "\n",
    "            # Query model to get action\n",
    "            action_chunk = client.infer(element)[\"actions\"]\n",
    "            assert (\n",
    "                len(action_chunk) >= args.replan_steps\n",
    "            ), f\"We want to replan every {args.replan_steps} steps, but policy only predicts {len(action_chunk)} steps.\"\n",
    "            action_plan.extend(action_chunk[: args.replan_steps])\n",
    "\n",
    "        action = action_plan.popleft()\n",
    "\n",
    "        # Execute action in environment\n",
    "        obs, reward, done, info = env.step(action.tolist())\n",
    "        if done:\n",
    "            task_successes += 1\n",
    "            total_successes += 1\n",
    "            break\n",
    "        t += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Caught exception: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7073619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('success',\n",
       " 'pick_up_the_black_bowl_between_the_plate_and_the_ramekin_and_place_it_on_the_plate')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_segment = task_description.replace(\" \", \"_\")\n",
    "suffix = \"success\" if done else \"failure\"\n",
    "suffix, task_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebc648c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving video to data/libero/videos/rollout_pick_up_the_black_bowl_between_the_plate_and_the_ramekin_and_place_it_on_the_plate_success.mp4\n"
     ]
    }
   ],
   "source": [
    "save_path = pathlib.Path(args.video_out_path) / f\"rollout_{task_segment}_{suffix}.mp4\"\n",
    "print(f\"Saving video to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b59953c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimwrite(save_path, [np.asarray(x) for x in replay_images], fps=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a9e19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f54c566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_chunk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7465bbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation/image: (224, 224, 3) \n",
      "observation/wrist_image: (224, 224, 3) \n",
      "observation/state: (8,) \n",
      "prompt: pick up the black bowl between the plate and the ramekin and place it on the plate\n"
     ]
    }
   ],
   "source": [
    "element.keys()\n",
    "for key in element:\n",
    "    if 'prompt' in key:\n",
    "        print(f\"{key}: {element[key]}\")\n",
    "    else:\n",
    "        print(f\"{key}: {element[key].shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3613a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e3920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
